{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "178e80501058c35a46f6801d06ede6ea",
     "grade": false,
     "grade_id": "cell-9885b323facdad84",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Codio Activity 9.7: Ridge vs. Sequential Feature Selection\n",
    "\n",
    "**Expected Time: 60 Minutes**\n",
    "\n",
    "**Total Points: 40**\n",
    "\n",
    "This activity focuses on comparing the results of a `Ridge` regression model with that of a `LinearRegression` model built using `SequentialFeatureSelector`.  Both of these approaches seek to limit the complexity of the model.  The `Ridge` estimator applies a penalty that shrinks the coefficients of the model while using the `SequentialFeatureSelector` selects a subset of features to build a model with.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "743122fce638c573dbb563433be626b7",
     "grade": false,
     "grade_id": "cell-686ed521942cdb92",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "#### Index\n",
    "\n",
    "- [Problem 1](#Problem-1)\n",
    "- [Problem 2](#Problem-2)\n",
    "- [Problem 3](#Problem-3)\n",
    "- [Problem 4](#Problem-4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "dadf240a6617c8d579d13a23922821a6",
     "grade": false,
     "grade_id": "cell-bc685dda5c83376a",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import set_config\n",
    "set_config(display=\"diagram\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0e73a05d7a17a4d704545b94930105a4",
     "grade": false,
     "grade_id": "cell-9d817f3e9eedd72c",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### The Insurance Data\n",
    "\n",
    "For this example, we return to the insurance data with cubic features.  Below the train and test data is loaded and the train and test sets are determined.  Recall that the target feature has the logarithm applied to it.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "deb57569603ec7c7a9fada15520b9587",
     "grade": false,
     "grade_id": "cell-5ba405bd2b8a324e",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/train_cubic.csv')\n",
    "test = pd.read_csv('data/test_cubic.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "da688a72b56e86e53ddf7973b8055055",
     "grade": false,
     "grade_id": "cell-b1be0f946b6eaeed",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "X_train, y_train = train.drop('target_log', axis = 1), train['target_log']\n",
    "X_test, y_test = test.drop('target_log', axis = 1), test['target_log']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "70ceefeeadfd21788f96ec57d2574910",
     "grade": false,
     "grade_id": "cell-a0efeb53332a708a",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Problem 1\n",
    "\n",
    "#### Feature Selection Pipeline\n",
    "\n",
    "**10 Points**\n",
    "\n",
    "To begin, use the pipeline below to construct a grid search over the `n_features_to_select` parameter of the `SequentialFeatureSelector` transformer.  Consider 2, 3, 4, and 5 features in your search.  Create the dictionary to be used in the search as `param_dict`.  \n",
    "\n",
    "Assign your grid to `selector_grid`, fit on the training data, and determine the mean squared error on the train and test set.  Assign the errors as floats to `selector_train_mse` and `selector_test_mse` respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0104a781298625255ec3d68b918719fd",
     "grade": false,
     "grade_id": "cell-805d087beeeb8b3b",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-60e4da24-1f74-4b19-bc27-58569f90b294 {color: black;background-color: white;}#sk-60e4da24-1f74-4b19-bc27-58569f90b294 pre{padding: 0;}#sk-60e4da24-1f74-4b19-bc27-58569f90b294 div.sk-toggleable {background-color: white;}#sk-60e4da24-1f74-4b19-bc27-58569f90b294 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-60e4da24-1f74-4b19-bc27-58569f90b294 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-60e4da24-1f74-4b19-bc27-58569f90b294 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-60e4da24-1f74-4b19-bc27-58569f90b294 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-60e4da24-1f74-4b19-bc27-58569f90b294 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-60e4da24-1f74-4b19-bc27-58569f90b294 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-60e4da24-1f74-4b19-bc27-58569f90b294 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-60e4da24-1f74-4b19-bc27-58569f90b294 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-60e4da24-1f74-4b19-bc27-58569f90b294 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-60e4da24-1f74-4b19-bc27-58569f90b294 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-60e4da24-1f74-4b19-bc27-58569f90b294 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-60e4da24-1f74-4b19-bc27-58569f90b294 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-60e4da24-1f74-4b19-bc27-58569f90b294 div.sk-estimator:hover {background-color: #d4ebff;}#sk-60e4da24-1f74-4b19-bc27-58569f90b294 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-60e4da24-1f74-4b19-bc27-58569f90b294 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-60e4da24-1f74-4b19-bc27-58569f90b294 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}#sk-60e4da24-1f74-4b19-bc27-58569f90b294 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;}#sk-60e4da24-1f74-4b19-bc27-58569f90b294 div.sk-item {z-index: 1;}#sk-60e4da24-1f74-4b19-bc27-58569f90b294 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;}#sk-60e4da24-1f74-4b19-bc27-58569f90b294 div.sk-parallel::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}#sk-60e4da24-1f74-4b19-bc27-58569f90b294 div.sk-parallel-item {display: flex;flex-direction: column;position: relative;background-color: white;}#sk-60e4da24-1f74-4b19-bc27-58569f90b294 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-60e4da24-1f74-4b19-bc27-58569f90b294 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-60e4da24-1f74-4b19-bc27-58569f90b294 div.sk-parallel-item:only-child::after {width: 0;}#sk-60e4da24-1f74-4b19-bc27-58569f90b294 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;position: relative;}#sk-60e4da24-1f74-4b19-bc27-58569f90b294 div.sk-label label {font-family: monospace;font-weight: bold;background-color: white;display: inline-block;line-height: 1.2em;}#sk-60e4da24-1f74-4b19-bc27-58569f90b294 div.sk-label-container {position: relative;z-index: 2;text-align: center;}#sk-60e4da24-1f74-4b19-bc27-58569f90b294 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-60e4da24-1f74-4b19-bc27-58569f90b294 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-60e4da24-1f74-4b19-bc27-58569f90b294\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;selector&#x27;,\n",
       "                 SequentialFeatureSelector(estimator=LinearRegression())),\n",
       "                (&#x27;model&#x27;, LinearRegression())])</pre><b>Please rerun this cell to show the HTML repr or trust the notebook.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"6dd99679-d38b-4b8d-a54b-747a46551a50\" type=\"checkbox\" ><label for=\"6dd99679-d38b-4b8d-a54b-747a46551a50\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;selector&#x27;,\n",
       "                 SequentialFeatureSelector(estimator=LinearRegression())),\n",
       "                (&#x27;model&#x27;, LinearRegression())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"73511af7-13ac-4168-9883-cbec94362036\" type=\"checkbox\" ><label for=\"73511af7-13ac-4168-9883-cbec94362036\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">selector: SequentialFeatureSelector</label><div class=\"sk-toggleable__content\"><pre>SequentialFeatureSelector(estimator=LinearRegression())</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"56546b40-973e-422e-b2c9-0cc25aa64bc5\" type=\"checkbox\" ><label for=\"56546b40-973e-422e-b2c9-0cc25aa64bc5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"0176cce1-596c-4c07-9b75-7cf4df67645b\" type=\"checkbox\" ><label for=\"0176cce1-596c-4c07-9b75-7cf4df67645b\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('selector',\n",
       "                 SequentialFeatureSelector(estimator=LinearRegression())),\n",
       "                ('model', LinearRegression())])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selector_pipe = Pipeline([('selector', SequentialFeatureSelector(LinearRegression())),\n",
    "                         ('model', LinearRegression())])\n",
    "selector_pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f65a32698c4da24f94239325a14efded",
     "grade": false,
     "grade_id": "cell-f580fcbb41258cf9",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train MSE: 0.6031734290034885\n",
      "Test MSE: 0.5655875591380699\n"
     ]
    }
   ],
   "source": [
    "### GRADED\n",
    "\n",
    "param_dict = {\"selector__n_features_to_select\":[2, 3, 4, 5]}\n",
    "selector_grid = GridSearchCV(estimator=selector_pipe, param_grid=param_dict).fit(X_train, y_train)\n",
    "selector_train_mse = mean_squared_error(selector_grid.predict(X_train), y_train)\n",
    "selector_test_mse = mean_squared_error(selector_grid.predict(X_test), y_test)\n",
    "\n",
    "# ANSWER CHECK\n",
    "print(f'Train MSE: {selector_train_mse}')\n",
    "print(f'Test MSE: {selector_test_mse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "33c90d621719ea04bd1e9fc70448900c",
     "grade": true,
     "grade_id": "cell-b991b67a5ac0214d",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d8e860180d5798ead5912e4f41ef6ff4",
     "grade": false,
     "grade_id": "cell-882a2f7363bd17d6",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Problem 2\n",
    "\n",
    "#### Ridge Grid\n",
    "\n",
    "**10 Points**\n",
    "\n",
    "Now, construct a `Pipeline` that contains two steps -- `scaler` and `ridge` that first standard scales the data and then build a ridge regression model.  Assign your pipeline as `ridge_pipe`.  Use this to execute the grid search over the `alpha` hyperparameter of the `Ridge` estimator using the training data. Determine the mean squared error on the train and test data. \n",
    "\n",
    "Assign the errors as floats to `ridge_train_mse` and `ridge_test_mse` respectively.\n",
    "\n",
    "\n",
    "Hint: \n",
    "\n",
    "Define a parameter dictionary named `ridge_param_dict` for the grid search. For this, use `np.logspace(0, 10, 50)` to create a range of alpha values `ridge__alpha`. This function generates values evenly spaced in logarithmic scale from 1 to 10^10. The parameter dictionary is specified as follows: `ridge_param_dict = {'ridge__alpha': np.logspace(0, 10, 50)}`.\n",
    "\n",
    "After defining `ridge_param_dict`, use it to execute the grid search over the alpha hyperparameter using the training data. Determine the mean squared error on the train and test data and assign the errors as floats to `ridge_train_mse` and `ridge_test_mse` respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1a3afd71fe635b6ae1d2a5d1c118bc68",
     "grade": false,
     "grade_id": "cell-b21362896fb19ee9",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train MSE: 0.5870277750390882\n",
      "Test MSE: 0.5532169282339894\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-237b2be8-2014-4be6-ad25-796e9450ae9f {color: black;background-color: white;}#sk-237b2be8-2014-4be6-ad25-796e9450ae9f pre{padding: 0;}#sk-237b2be8-2014-4be6-ad25-796e9450ae9f div.sk-toggleable {background-color: white;}#sk-237b2be8-2014-4be6-ad25-796e9450ae9f label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-237b2be8-2014-4be6-ad25-796e9450ae9f label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-237b2be8-2014-4be6-ad25-796e9450ae9f label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-237b2be8-2014-4be6-ad25-796e9450ae9f div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-237b2be8-2014-4be6-ad25-796e9450ae9f div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-237b2be8-2014-4be6-ad25-796e9450ae9f div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-237b2be8-2014-4be6-ad25-796e9450ae9f input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-237b2be8-2014-4be6-ad25-796e9450ae9f input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-237b2be8-2014-4be6-ad25-796e9450ae9f div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-237b2be8-2014-4be6-ad25-796e9450ae9f div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-237b2be8-2014-4be6-ad25-796e9450ae9f input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-237b2be8-2014-4be6-ad25-796e9450ae9f div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-237b2be8-2014-4be6-ad25-796e9450ae9f div.sk-estimator:hover {background-color: #d4ebff;}#sk-237b2be8-2014-4be6-ad25-796e9450ae9f div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-237b2be8-2014-4be6-ad25-796e9450ae9f div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-237b2be8-2014-4be6-ad25-796e9450ae9f div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}#sk-237b2be8-2014-4be6-ad25-796e9450ae9f div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;}#sk-237b2be8-2014-4be6-ad25-796e9450ae9f div.sk-item {z-index: 1;}#sk-237b2be8-2014-4be6-ad25-796e9450ae9f div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;}#sk-237b2be8-2014-4be6-ad25-796e9450ae9f div.sk-parallel::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}#sk-237b2be8-2014-4be6-ad25-796e9450ae9f div.sk-parallel-item {display: flex;flex-direction: column;position: relative;background-color: white;}#sk-237b2be8-2014-4be6-ad25-796e9450ae9f div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-237b2be8-2014-4be6-ad25-796e9450ae9f div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-237b2be8-2014-4be6-ad25-796e9450ae9f div.sk-parallel-item:only-child::after {width: 0;}#sk-237b2be8-2014-4be6-ad25-796e9450ae9f div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;position: relative;}#sk-237b2be8-2014-4be6-ad25-796e9450ae9f div.sk-label label {font-family: monospace;font-weight: bold;background-color: white;display: inline-block;line-height: 1.2em;}#sk-237b2be8-2014-4be6-ad25-796e9450ae9f div.sk-label-container {position: relative;z-index: 2;text-align: center;}#sk-237b2be8-2014-4be6-ad25-796e9450ae9f div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-237b2be8-2014-4be6-ad25-796e9450ae9f div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-237b2be8-2014-4be6-ad25-796e9450ae9f\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()), (&#x27;ridge&#x27;, Ridge())])</pre><b>Please rerun this cell to show the HTML repr or trust the notebook.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"57b69728-9f7f-4252-aa19-e4f54582fb6b\" type=\"checkbox\" ><label for=\"57b69728-9f7f-4252-aa19-e4f54582fb6b\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()), (&#x27;ridge&#x27;, Ridge())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"ac80db0d-4c2b-4c03-8918-1b656b2e4287\" type=\"checkbox\" ><label for=\"ac80db0d-4c2b-4c03-8918-1b656b2e4287\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"c9dcc958-855f-4aba-8dbe-716bbb170e91\" type=\"checkbox\" ><label for=\"c9dcc958-855f-4aba-8dbe-716bbb170e91\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Ridge</label><div class=\"sk-toggleable__content\"><pre>Ridge()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('scaler', StandardScaler()), ('ridge', Ridge())])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### GRADED\n",
    "\n",
    "ridge_param_dict = {'ridge__alpha': np.logspace(0, 10, 50)}\n",
    "ridge_pipe = Pipeline([('scaler', StandardScaler()), ('ridge', Ridge())])\n",
    "ridge_grid = GridSearchCV(\n",
    "    estimator=ridge_pipe,\n",
    "    param_grid=ridge_param_dict).fit(X_train, y_train)\n",
    "ridge_train_mse = mean_squared_error(ridge_grid.predict(X_train), y_train)\n",
    "ridge_test_mse = mean_squared_error(ridge_grid.predict(X_test), y_test)\n",
    "\n",
    "# ANSWER CHECK\n",
    "print(f'Train MSE: {ridge_train_mse}')\n",
    "print(f'Test MSE: {ridge_test_mse}')\n",
    "ridge_pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "46a80fa83c96465dcc8be2cb6f31b28c",
     "grade": true,
     "grade_id": "cell-fd8d23006d29b981",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b977c0502ff64e6ae80c40e9aa8ccc96",
     "grade": false,
     "grade_id": "cell-dc0d54dcdc797fd0",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Problem 3\n",
    "\n",
    "#### Examining the \"best\" model\n",
    "\n",
    "**10 Points**\n",
    "\n",
    "Your results should suggest that the model using the sequential feature selector and `LinearRegression` estimator.  This was fit with the object `selector_grid`.  One question we may have is what was the optimal number of features selected and what were they?  \n",
    "\n",
    "Use the `selector_grid` to extract both the feature names and their associated coefficients.  This will involve:\n",
    "\n",
    "- `.best_estimator_`: extract the best estimator/selector pair from your grid search\n",
    "- `.named_steps['selector']`: extract the selector from the pipeline\n",
    "- `.named_steps['model']`: extract the model from the pipeline\n",
    "- `.get_support()`: extract best features from selector.  This returns booleans as to whether feature was selected, we can use this to slice our train data.  \n",
    "\n",
    "```python\n",
    "X_train.columns[best_selector.get_support()]\n",
    "```\n",
    "\n",
    "- `.coef_`: coefficients from best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3664f8586f532b4fbabac21efbca4e7b",
     "grade": false,
     "grade_id": "cell-086dc1fb9b5bad93",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('selector',\n",
      "                 SequentialFeatureSelector(estimator=LinearRegression(),\n",
      "                                           n_features_to_select=2)),\n",
      "                ('model', LinearRegression())])\n",
      "Features from best selector: ['age' 'bmi children'].\n",
      "Coefficient values: \n",
      "===================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>bmi children</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <td>0.032852</td>\n",
       "      <td>0.00368</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            age  bmi children\n",
       "model  0.032852       0.00368"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### GRADED\n",
    "\n",
    "best_estimator = selector_grid.best_estimator_\n",
    "best_selector = best_estimator.named_steps['selector']\n",
    "best_model = best_estimator.named_steps['model']\n",
    "feature_names = best_selector.get_feature_names_out()\n",
    "coefs = best_model.coef_\n",
    "\n",
    "# Answer check\n",
    "print(best_estimator)\n",
    "print(f'Features from best selector: {feature_names}.')\n",
    "print('Coefficient values: ')\n",
    "print('===================')\n",
    "pd.DataFrame([coefs.T], columns = feature_names, index = ['model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "60f998c3ef42dc28766d4fdb1508ed62",
     "grade": true,
     "grade_id": "cell-727135aa3ceb8535",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "cebb6f054e6e37fdf5cdcc0bf857266d",
     "grade": false,
     "grade_id": "cell-b828dc090256f1c7",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Problem 4\n",
    "\n",
    "#### Comparing observations \n",
    "\n",
    "**10 Points**\n",
    "\n",
    "According to your model, predict the billed costs for person 1 and person 2 below:\n",
    "\n",
    "- **Person 1**: Age = 30, bmi = 40, children = 0\n",
    "- **Person 2**: Age = 45, bmi = 50, children = 2\n",
    "\n",
    "Use the information from **Problem 3** and the model coefficients to make these predictions.\n",
    "\n",
    "Note that you will want to transform your predictions.  From your model the predictions are in terms of the logarithm of cost.  To transform the logarithm to the actual value, use `np.exp` -- the inverse of a logarithm. Assign your predictions as floats to `person1` and `person2` below.  Your solution will be checked to two decimal point accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "467ba1928c9005036f4abea05fd4f54e",
     "grade": false,
     "grade_id": "cell-51bce4efc95aa858",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The difference between Person 1 and Person 2 is  8052.04\n"
     ]
    }
   ],
   "source": [
    "### GRADED\n",
    "ages = [30, 45]\n",
    "bmis = [40, 50]\n",
    "childrens = [0, 2]\n",
    "person1 = float(np.exp(best_model.predict([[ages[0], bmis[0]*childrens[0]]])))\n",
    "person2 = float(np.exp(best_model.predict([[ages[1], bmis[1]*childrens[1]]])))\n",
    "# display(np.exp(best_model.predict(pd.DataFrame({\"age\":ages, \"bmi children\":np.array(bmis)*np.array(childrens)}))))\n",
    "# display(np.exp(best_model.predict([[ages[0], bmis[0]*childrens[0]]])))\n",
    "\n",
    "# Answer check\n",
    "print(f'The difference between Person 1 and Person 2 is {person2 - person1: .2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ae757f739ba4b47d2bedff42233766b6",
     "grade": true,
     "grade_id": "cell-5bb5e273c425e0a8",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "bd4a2bfa52681495872277f3faa39d93",
     "grade": false,
     "grade_id": "cell-5d53afcbf13ed189",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "The models here could be revisited and more encoding of features and different polynomial terms can be incorporated.  More important is understanding how to construct the pipelines and interrogate the resulting models to understand what they say about your data.  Does having a higher body mass matter if one does not have children?  Does this seem reasonable?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
