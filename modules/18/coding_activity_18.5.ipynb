{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "bd4f80cf4eb1b78da3f55f96729a628c",
     "grade": false,
     "grade_id": "cell-db224a67ee548c23",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Codio Activity 18.5: Tfidf\n",
    "\n",
    "**Expected Time = 90 minutes** \n",
    "\n",
    "**Total Points = 60** \n",
    "\n",
    "This activity focuses on using term frequency inverse document frequency (tfidf) to vectorize text.  First, you will compute tfidf by hand on a small example.  Then, you will use scikitlearn to implement the `TfidfVectorizer` together with a `LogisticRegression` estimator to see if the performance on predicting the WhatsApp status improves with a different representation.\n",
    "\n",
    "- [Problem 1](#-Problem-1)\n",
    "- [Problem 2](#-Problem-2)\n",
    "- [Problem 3](#-Problem-3)\n",
    "- [Problem 4](#-Problem-4)\n",
    "- [Problem 5](#-Problem-5)\n",
    "- [Problem 6](#-Problem-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "38a7479eb91ebacb413c88751bf2f108",
     "grade": false,
     "grade_id": "cell-59d0134b4198708d",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Small Example\n",
    "\n",
    "As discussed in the lectures, the formula for tfidf is given as:\n",
    "\n",
    "$$\\text{tfidf} = \\frac{\\text{term frequency}}{\\text{inverse document frequency}}$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = [\n",
    "    [\"The\", \"burritos\", \"were\", \"not\", \"great\"],\n",
    "    [\"The\", \"burritos\", \"were\", \"great\", \"great\", \"great\"],\n",
    "    [\"The\", \"taco\", \"was\", \"good\"],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['The', 'burritos', 'were', 'not', 'great'],\n",
       " ['The', 'burritos', 'were', 'great', 'great', 'great'],\n",
       " ['The', 'taco', 'was', 'good']]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "708954d71116df16ac801c0fcfabdc4b",
     "grade": false,
     "grade_id": "cell-9d9a50d8ff026af5",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#-Index)\n",
    "\n",
    "\n",
    "### Problem 1\n",
    "\n",
    "#### Term Frequency\n",
    "\n",
    "**10 Points** \n",
    "\n",
    "$$tf(t, d) = \\frac{\\text{number of times that t occurs in d}} {\\text{number of words in d}}$$\n",
    "\n",
    "Compute the tf scores for the three documents in `tokens` for the word **great**.  Assign as a list of floats to `tfs` below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e7699ca9be5a311a0013f0c165bcb09c",
     "grade": false,
     "grade_id": "cell-0f20a1dc9861cd6e",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, [0.2, 0.5, 0.0]]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### GRADED\n",
    "tfs = [\n",
    "    sum([w == \"great\" for w in tokens[k]]) / len(tokens[k]) for k in range(len(tokens))\n",
    "]\n",
    "\n",
    "### ANSWER CHECK\n",
    "[len(tfs), tfs]  # should be 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "eb8c3a553f152b3d028d147ab7b3d02d",
     "grade": false,
     "grade_id": "cell-1b37ac1818364fe8",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#-Index)\n",
    "\n",
    "\n",
    "### Problem 2\n",
    "\n",
    "#### Inverse document frequency\n",
    "\n",
    "**10 Points** \n",
    "\n",
    "The inverse document frequency is given by the formula:\n",
    "\n",
    "$$idf(t) = -\\log(\\frac{\\text{number of documents that contain t}}{\\text{total number of documents}})$$\n",
    "\n",
    "Compute the idf score for the word great.  Assign as a float to `idf` below. Be sure to use `np.log` to compute the logarithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "31229e52f59519193ac05893f12cd6a8",
     "grade": false,
     "grade_id": "cell-cf7e1288721ed647",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.40546510810816444\n"
     ]
    }
   ],
   "source": [
    "### GRADED\n",
    "idf = -np.log(sum([\"great\" in tokens[k] for k in range(len(tokens))]) / len(tokens))\n",
    "\n",
    "### ANSWER CHECK\n",
    "print(idf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e7d8e2afc8013c7929bb6aecacac5e9d",
     "grade": false,
     "grade_id": "cell-9cbb357ea8b09ee1",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#-Index)\n",
    "\n",
    "\n",
    "### Problem 3\n",
    "\n",
    "####  tfidf by hand\n",
    "\n",
    "**10 Points** \n",
    "\n",
    "Now, combine the tf and idf scores to compute the tfidf as:\n",
    "\n",
    "$$tfidf(t, d) = tf(t, d) \\times idf(t)$$\n",
    "\n",
    "for the word \"great\".  Assign your solution as a list of floats to `tfidfs` below.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3bee5a74c356cd5cd145fceb519caaf4",
     "grade": false,
     "grade_id": "cell-ebcaf0cf8e986b00",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0810930216216329, 0.20273255405408222, 0.0]\n"
     ]
    }
   ],
   "source": [
    "### GRADED\n",
    "tfidfs = [tf * idf for tf in tfs]\n",
    "\n",
    "\n",
    "### ANSWER CHECK\n",
    "print(tfidfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ab11533807d4b5949b5f4c22a77b1f4f",
     "grade": false,
     "grade_id": "cell-85f13f77e80ec11f",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#-Index)\n",
    "\n",
    "\n",
    "### Problem 4\n",
    "\n",
    "#### Using `TfidfVectorizer` in a `Pipeline`\n",
    "\n",
    "**10 Points** \n",
    "\n",
    "Now, you are to use the scikitlearn transformer `TfidfVectorizer` to transform the WhatsApp data from kaggle.  The data is loaded and split below. \n",
    "\n",
    "Create a `TfidfVectorizer`, assigning it to the variable `tfidif`. Fit it with the training data and assign it to the variable `dtm`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "happy_df = pd.read_csv(\"data/Emotion(happy).csv\")\n",
    "sad_df = pd.read_csv(\"data/Emotion(sad).csv.zip\", compression=\"zip\")\n",
    "full_df = pd.concat([happy_df, sad_df]).reset_index(drop=True)\n",
    "X = full_df.drop(\"sentiment\", axis=1)\n",
    "y = full_df[\"sentiment\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X[\"content\"], y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "24e8788bc7eee46bafd1a51b01b70193",
     "grade": false,
     "grade_id": "cell-8321ab6d6dbc182e",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0_0</th>\n",
       "      <th>100</th>\n",
       "      <th>123whatsappstatus</th>\n",
       "      <th>204</th>\n",
       "      <th>30</th>\n",
       "      <th>404</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>55</th>\n",
       "      <th>805</th>\n",
       "      <th>...</th>\n",
       "      <th>yes</th>\n",
       "      <th>yesterday</th>\n",
       "      <th>yet</th>\n",
       "      <th>you</th>\n",
       "      <th>young</th>\n",
       "      <th>your</th>\n",
       "      <th>yours</th>\n",
       "      <th>yourself</th>\n",
       "      <th>yous</th>\n",
       "      <th>yuh</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01397</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006924</td>\n",
       "      <td>0.398355</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.070646</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01305</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.184358</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 1832 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0_0  100  123whatsappstatus  204   30  404   44   45   55  805  ...  \\\n",
       "0  0.0  0.0                0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   \n",
       "1  0.0  0.0                0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   \n",
       "2  0.0  0.0                0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   \n",
       "3  0.0  0.0                0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   \n",
       "4  0.0  0.0                0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   \n",
       "\n",
       "       yes  yesterday       yet       you  young      your  yours  yourself  \\\n",
       "0  0.01397        0.0  0.006924  0.398355    0.0  0.070646    0.0   0.01305   \n",
       "1  0.00000        0.0  0.000000  0.184358    0.0  0.000000    0.0   0.00000   \n",
       "2  0.00000        0.0  0.000000  0.000000    0.0  0.000000    0.0   0.00000   \n",
       "3  0.00000        0.0  0.000000  0.000000    0.0  0.000000    0.0   0.00000   \n",
       "4  0.00000        0.0  0.000000  0.000000    0.0  0.000000    0.0   0.00000   \n",
       "\n",
       "   yous  yuh  \n",
       "0   0.0  0.0  \n",
       "1   0.0  0.0  \n",
       "2   0.0  0.0  \n",
       "3   0.0  0.0  \n",
       "4   0.0  0.0  \n",
       "\n",
       "[5 rows x 1832 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### GRADED\n",
    "tfidf = TfidfVectorizer()\n",
    "dtm = tfidf.fit_transform(X_train, y_train)\n",
    "\n",
    "\n",
    "### ANSWER CHECK\n",
    "pd.DataFrame(dtm.toarray(), columns=tfidf.get_feature_names_out()).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7a6fbe36115f3b173f9e04eb6d968cef",
     "grade": false,
     "grade_id": "cell-f01a2f3c5c589348",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#-Index)\n",
    "\n",
    "\n",
    "### Problem 5\n",
    "\n",
    "#### Pipeline with `TfidfVectorizer`\n",
    "\n",
    "**10 Points** \n",
    "\n",
    "Now, create a pipeline named `tfidf_pipe` below.  This should have named step `tfidf` and `lgr` and implement a `TfidfVectorizer` and `LogisticRegression` estimator respectively.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c311d28319cb55aee878f5eaf9c632f1",
     "grade": false,
     "grade_id": "cell-ec931b1d5b5f5f97",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'tfidf': TfidfVectorizer(), 'lgr': LogisticRegression()}, 0.7946428571428571]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### GRADED\n",
    "tfidf_pipe = Pipeline(\n",
    "    [\n",
    "        (\"tfidf\", TfidfVectorizer()),\n",
    "        (\"lgr\", LogisticRegression()),\n",
    "    ]\n",
    ").fit(X_train, y_train)\n",
    "\n",
    "test_acc = tfidf_pipe.score(X_test, y_test)\n",
    "\n",
    "[\n",
    "    tfidf_pipe.named_steps,\n",
    "    test_acc,\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8c54cee2a7ca6f45466220b37f5aaf0f",
     "grade": false,
     "grade_id": "cell-ab85db9f9553efeb",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#-Index)\n",
    "\n",
    "\n",
    "### Problem 6\n",
    "\n",
    "#### Grid Searching the Pipeline\n",
    "\n",
    "**10 Points** \n",
    "\n",
    "Use the parameter grid below to create a grid search object named `tfidf_grid` using your pipeline `tfidf_pipe` and the parameter grid given.  Assess the performance on the test set as `tfidf_acc` and consider how this representation of the text compared to the pure counts of `CountVectorizer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"tfidf__max_features\": [100, 500, 1000, 2000],\n",
    "    \"tfidf__stop_words\": [\"english\", None],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1f34d1c521342cf0174f9a5848239599",
     "grade": false,
     "grade_id": "cell-bd3ca378e66824f5",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tfidf__max_features': 500, 'tfidf__stop_words': None}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### GRADED\n",
    "grid = GridSearchCV(estimator=tfidf_pipe, param_grid=params).fit(X_train, y_train)\n",
    "test_acc = grid.best_estimator_.score(X_test, y_test)\n",
    "\n",
    "### ANSWER CHECK\n",
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8669314796425025, 0.7946428571428571]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[\n",
    "    grid.score(X_train, y_train),\n",
    "    grid.score(X_test, y_test),\n",
    "]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
