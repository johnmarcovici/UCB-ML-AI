{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6cf5e4e4461324c828b60586a159a180",
     "grade": false,
     "grade_id": "cell-b3b2d417bfed0767",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Codio Activity 22.9: End to End Classification with `keras`\n",
    "\n",
    "**Expected Time = 60 minutes**\n",
    "\n",
    "**Total Points = 20**\n",
    "\n",
    "This activity focuses on using a dataset that contains a mix of feature types to build a binary classification model.  You will use familiar scikit-learn preprocessing operations to handle categorical features, and use the transformed data together with a `keras` model.  After building a familiar model, further examples are shown using regularization strategies for neural networks.\n",
    "\n",
    "#### Index\n",
    "\n",
    "- [Problem 1](#-Problem-1)\n",
    "- [Problem 2](#-Problem-2)\n",
    "- [Problem 3](#-Problem-3)\n",
    "- [Problem 4](#-Problem-4)\n",
    "- [Problem 5](#-Problem-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5a4e7f0fe41d9c820f8984c65baa7faf",
     "grade": false,
     "grade_id": "cell-9a02f3a1d08dfb98",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### The Data\n",
    "\n",
    "The dataset contains information gathered from the United States Census about whether or not the individual earned over \\$50,000 per year. ([more info here](https://archive.ics.uci.edu/ml/datasets/Adult))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/adult.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education.num</th>\n",
       "      <th>marital.status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital.gain</th>\n",
       "      <th>capital.loss</th>\n",
       "      <th>hours.per.week</th>\n",
       "      <th>native.country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90</td>\n",
       "      <td>?</td>\n",
       "      <td>77053</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>?</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>4356</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>82</td>\n",
       "      <td>Private</td>\n",
       "      <td>132870</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>4356</td>\n",
       "      <td>18</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>66</td>\n",
       "      <td>?</td>\n",
       "      <td>186061</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>?</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>4356</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>54</td>\n",
       "      <td>Private</td>\n",
       "      <td>140359</td>\n",
       "      <td>7th-8th</td>\n",
       "      <td>4</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>3900</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>Private</td>\n",
       "      <td>264663</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Separated</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>3900</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age workclass  fnlwgt     education  education.num marital.status  \\\n",
       "0   90         ?   77053       HS-grad              9        Widowed   \n",
       "1   82   Private  132870       HS-grad              9        Widowed   \n",
       "2   66         ?  186061  Some-college             10        Widowed   \n",
       "3   54   Private  140359       7th-8th              4       Divorced   \n",
       "4   41   Private  264663  Some-college             10      Separated   \n",
       "\n",
       "          occupation   relationship   race     sex  capital.gain  \\\n",
       "0                  ?  Not-in-family  White  Female             0   \n",
       "1    Exec-managerial  Not-in-family  White  Female             0   \n",
       "2                  ?      Unmarried  Black  Female             0   \n",
       "3  Machine-op-inspct      Unmarried  White  Female             0   \n",
       "4     Prof-specialty      Own-child  White  Female             0   \n",
       "\n",
       "   capital.loss  hours.per.week native.country income  \n",
       "0          4356              40  United-States  <=50K  \n",
       "1          4356              18  United-States  <=50K  \n",
       "2          4356              40  United-States  <=50K  \n",
       "3          3900              40  United-States  <=50K  \n",
       "4          3900              40  United-States  <=50K  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 32561 entries, 0 to 32560\n",
      "Data columns (total 15 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   age             32561 non-null  int64 \n",
      " 1   workclass       32561 non-null  object\n",
      " 2   fnlwgt          32561 non-null  int64 \n",
      " 3   education       32561 non-null  object\n",
      " 4   education.num   32561 non-null  int64 \n",
      " 5   marital.status  32561 non-null  object\n",
      " 6   occupation      32561 non-null  object\n",
      " 7   relationship    32561 non-null  object\n",
      " 8   race            32561 non-null  object\n",
      " 9   sex             32561 non-null  object\n",
      " 10  capital.gain    32561 non-null  int64 \n",
      " 11  capital.loss    32561 non-null  int64 \n",
      " 12  hours.per.week  32561 non-null  int64 \n",
      " 13  native.country  32561 non-null  object\n",
      " 14  income          32561 non-null  object\n",
      "dtypes: int64(6), object(9)\n",
      "memory usage: 3.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(\"income\", axis=1)\n",
    "y = df[\"income\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7240c615d0a6ae9585cb2878c1d83a34",
     "grade": false,
     "grade_id": "cell-debcec427ec26222",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "[Back to top](#-Index)\n",
    "\n",
    "### Problem 1\n",
    "\n",
    "#### Preparing the Data\n",
    "\n",
    "**10 Points**\n",
    "\n",
    "Below, use the `make_column_transformer` to transform the feature array as `X_train_num` and `X_test_num` using the `OneHotEncoder` with `drop = if_binary` and existing numeric data should be scaled using `StandardScaler`.  \n",
    "\n",
    "For the target, assign the values of `y_train_num` and `y_test_num` as a binary array where 1 represents observations earning over \\$50,000 per year, and 0 less.  Note that as long as you have a purely numeric array, the `keras` model will accept this as input.  While you can use a sparse array, here you are to transform the sparse array to a dense array with the `.toarray()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['<=50K', '>50K'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.unique()  # unique values of y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<=50K    0.75919\n",
       ">50K     0.24081\n",
       "Name: income, dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts(normalize=True)  # baseline for model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "752b56326a2ba42543327edd0e2bf121",
     "grade": false,
     "grade_id": "cell-bcd0e55ebe7bcaa1",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1]\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "### GRADED\n",
    "transformer = make_column_transformer(\n",
    "    (\n",
    "        OneHotEncoder(drop=\"if_binary\"),\n",
    "        df.select_dtypes(\"object\").columns[:-1],\n",
    "    ),\n",
    "    remainder=StandardScaler(),\n",
    ").fit(X_train)\n",
    "X_train_num = transformer.transform(X_train).toarray()\n",
    "X_test_num = transformer.transform(X_test).toarray()\n",
    "\n",
    "y_train_num = y_train.map({\">50K\": 1, \"<=50K\": 0})\n",
    "y_test_num = y_test.map({\">50K\": 1, \"<=50K\": 0})\n",
    "\n",
    "\n",
    "### ANSWER CHECK\n",
    "print(np.unique(y_train_num))\n",
    "print(type(X_train_num))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8f9901ac3f75d6bd5b0edd2b1e37525c",
     "grade": false,
     "grade_id": "cell-1481dab390d2772c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "[Back to top](#-Index)\n",
    "\n",
    "### Problem 2\n",
    "\n",
    "#### Building the model\n",
    "\n",
    "**10 Points**\n",
    "\n",
    "Now, use `keras` to build a model using a single hidden layer using 50 units and a single output layer, naming the model `model1`.  Fit the model and work to build a model using 10 training epochs.  Note the accuracy on the validation set.\n",
    "\n",
    "NOTE: This question is computationally expensive and may take a minute or two to complete calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5e8993d6ce0b20df87f1bb83f745f92a",
     "grade": false,
     "grade_id": "cell-288e9367eed17065",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.861670732498169\n",
      "0.8581255078315735\n"
     ]
    }
   ],
   "source": [
    "### GRADED\n",
    "tf.random.set_seed(42)\n",
    "model1 = tf.keras.Sequential(\n",
    "    [\n",
    "        Dense(50, activation=\"relu\"),\n",
    "        Dense(1, activation=\"sigmoid\"),\n",
    "    ]\n",
    ")\n",
    "model1.compile(optimizer=\"rmsprop\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "history1 = model1.fit(\n",
    "    x=X_train_num,\n",
    "    y=y_train_num,\n",
    "    epochs=10,\n",
    "    verbose=0,\n",
    "    validation_data=(X_test_num, y_test_num),\n",
    ")\n",
    "\n",
    "### ANSWER CHECK\n",
    "print(history1.history[\"accuracy\"][-1])\n",
    "print(history1.history[\"val_accuracy\"][-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b13cbf9084fd3c736e8eb54433bbf607",
     "grade": false,
     "grade_id": "cell-f47a122152b4c88d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Exploring Regularization\n",
    "\n",
    "Below, the questions introduce the notion of regularization in your `keras` models.  The following questions are not graded, but are meant to offer exploratory introduction to using regularization in the neural network.  This may or may not improve our model for income -- but they are important components of some advanced architectures including those coming in the next module."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "433037403d027160c2d83250d6107b35",
     "grade": false,
     "grade_id": "cell-04c00ba81b855d55",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "[Back to top](#-Index)\n",
    "\n",
    "### Problem 3\n",
    "\n",
    "#### Regularization in the Network\n",
    "\n",
    "Similar to what we have seen in early models, there are some options for regularization in your neural network.  Below, `model2` uses `kernel_regularizer = 'l1'` to apply L1 regularization to the hidden layer.  \n",
    "\n",
    "Explore other options built in to the `Dense` layer for regularization and see if applying either `l1` or `l2` regularization to the kernel and bias elements of the hidden layer.  \n",
    "\n",
    "Assign your new model as `model2` below, and the fit information as `history2` below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Sequential()\n",
    "model2.add(Dense(50, activation=\"relu\", kernel_regularizer=\"l1\"))\n",
    "model2.add(Dense(1, activation=\"sigmoid\"))\n",
    "model2.compile(loss=\"bce\", metrics=[\"acc\"])\n",
    "history2 = model2.fit(\n",
    "    X_train_num,\n",
    "    y_train_num,\n",
    "    validation_data=(X_test_num, y_test_num),\n",
    "    epochs=10,\n",
    "    verbose=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8475430011749268\n",
      "0.8432624936103821\n"
     ]
    }
   ],
   "source": [
    "print(history2.history[\"acc\"][-1])\n",
    "print(history2.history[\"val_acc\"][-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6d6e6f9d013e49c9aa980207d16c8bea",
     "grade": false,
     "grade_id": "cell-28c2788d980f8547",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "[Back to top](#-Index)\n",
    "\n",
    "### Problem 4\n",
    "\n",
    "#### Dropout\n",
    "\n",
    "An alternative option for regularization is the `Dropout` layer.  This layer randomly \"drops out\" nodes in a given layer.  From the `keras` documentation:\n",
    "\n",
    "```\n",
    "The Dropout layer randomly sets input units to 0 with a frequency of rate at each step during training time, which helps prevent overfitting. Inputs not set to 0 are scaled up by 1/(1 - rate) such that the sum over all inputs is unchanged.\n",
    "```\n",
    "\n",
    "To use this, the code below creates a model where 20% of the nodes in the hidden layer will be randomly dropped in each training epoch.  Experiment with this model and incorporate other regularization strategies from above to see if you can improve the performance of predictions on the validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = Sequential()\n",
    "model3.add(Dense(50, activation=\"relu\"))\n",
    "model3.add(Dropout(0.2))\n",
    "model3.add(Dense(1, activation=\"sigmoid\"))\n",
    "model3.compile(loss=\"bce\", metrics=[\"acc\"])\n",
    "history3 = model3.fit(\n",
    "    X_train_num,\n",
    "    y_train_num,\n",
    "    validation_data=(X_test_num, y_test_num),\n",
    "    epochs=10,\n",
    "    verbose=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8614659905433655\n",
      "0.8560373187065125\n"
     ]
    }
   ],
   "source": [
    "print(history3.history[\"acc\"][-1])\n",
    "print(history3.history[\"val_acc\"][-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d1214a50c7db6aa1d71b8d5c98a2e6e4",
     "grade": false,
     "grade_id": "cell-3e7d51b8df6b4f77",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "[Back to top](#-Index)\n",
    "\n",
    "### Problem 5\n",
    "\n",
    "#### Early Stopping\n",
    "\n",
    "A third option for regularization is *Early Stopping*.  Here, you can set the model to stop training when overfitting begins.  Overfitting can be defined as the difference between training and validation data during each epoch of training.\n",
    "\n",
    "To use this in `keras` you use a *callback*.  This is an object that is created and passed as an argument during the fitting of the model.  Below, the code demonstrates the use of the `EarlyStopping` callback from `keras`. Use this to explore alternative settings with both `Dropout` and kernel regularization to see if you can improve the performance of the network.\n",
    "\n",
    "Plot the training and validation data to explore how early stopping truncated the training when overfitting begins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopper = EarlyStopping(patience=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4 = Sequential()\n",
    "model4.add(Dense(50, activation=\"relu\"))\n",
    "model4.add(Dropout(0.2))\n",
    "model4.add(Dense(1, activation=\"sigmoid\"))\n",
    "model4.compile(loss=\"bce\", metrics=[\"acc\"])\n",
    "history4 = model4.fit(\n",
    "    X_train_num,\n",
    "    y_train_num,\n",
    "    validation_data=(X_test_num, y_test_num),\n",
    "    epochs=1,\n",
    "    verbose=0,\n",
    "    callbacks=stopper,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8411957621574402\n",
      "0.8501412868499756\n"
     ]
    }
   ],
   "source": [
    "print(history4.history[\"acc\"][-1])\n",
    "print(history4.history[\"val_acc\"][-1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
